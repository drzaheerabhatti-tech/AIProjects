# data_ai.py
AI_DOCS = [
    "Transformer models use self-attention to process tokens in parallel, enabling strong language understanding.",
    "RAG (Retrieval-Augmented Generation) combines retrieval over documents with a generator to produce grounded answers from sources.",
    "LLM hallucinations are confident statements not supported by evidence; grounding and verification reduce them.",
    "Reinforcement learning optimizes policies using rewards; it differs from supervised learning which learns from labeled examples.",
    "Diffusion models generate images by iteratively denoising noise toward a target distribution.",
    "Evaluation of LLMs can include factuality, instruction-following, bias, and robustness to adversarial prompts."
]

QUERY = "How does RAG reduce hallucinations?"
